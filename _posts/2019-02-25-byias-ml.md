---
layout: post
title: ML概率相关的几个名词
category: 算法
comments: true
description: ML概率相关的几个名词
keywords: 机器学习,先验概率,后验概率,条件概率,极大似然,贝叶斯
---

概率中的各种概率名词，统一整理。

先验概率: 事件X发生的概率P(X)叫做先验概率。一般通过统计获得

条件概率： 事件X在条件Y的情况下发生的概率P(X|Y)叫做条件Y下X的条件概率，又叫似然概率，一般通过统计获得

后验概率: 事件X发生的条件下Y发生的概率P(Y|X)叫做X的后验概率。事件发生后求的反向条件概率

贝叶斯公式:

P(X|Y) = P(X,Y)/P(Y)


P(Y|X) = P(X,Y)/P(X)


P(Y|X) = P(X|Y)P(Y)/P(X)

贝叶斯决策: 若Y是Y样本X的分类标签，P(Y|X)最大的类别作为判别结果。P(Y|X)=P(X|Y)P(Y)/P(X)

一般的，先验概率可以通过统计得到。条件概率P(X|Y)由于条件组合多，一般无法使用统计获取。解决的办法就是，把估计完全未知的条件概率分布转化为估计参数。这里就将概率密度估计问题转化为参数估计问题，极大似然估计就是一种参数估计方法。


最大似然估计的目的就是：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。

对于函数:P(x|θ)

输入有两个：x表示某一个具体的数据；θ表示模型的参数。

如果θ是已知确定的，x是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。

如果xx是已知确定的，θ是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现x这个样本点的概率是多少。

### 最大似然估计（MLE）

给定一堆数据，假如我们知道它是从某一种分布中随机取出来的，可是我们并不知道这个分布具体的参，即“模型已定，参数未知”。例如，我们知道这个分布是正态分布，但是不知道均值和方差；MLE的目标是找出一组参数，使得模型产生出观测数据的概率最大：

$$argmax p(X;\mu) $$ 

其中$p(X;\mu)$叫做似然函数，表示在参数$\mu$下出现观测数据的概率.

$$log p(X;\mu)=\prod_{i=1}^n p(x_i|\mu)$$

为了计算方便，一般取对数似然:
$$p(X;\mu)=\sum_{i=1}^n log( p(x_i|\mu) )$$

对对数似然函数求导，使得导数为0，求出参数$\mu$




### 最大后验概率估计（MAP）

最大似然估计是求参数$\mu$, 使似然函数$p(X;\mu)$最大。最大后验概率估计则是想求$\mu$使$ p(X|\mu)p(\mu) $最大。求得的$\mu$不单单让似然函数大，$\mu$自己出现的先验概率也得大。

实际上，最大后验概率是求$p(\mu|X)=\frac{p(X|\mu)p(\mu)} {p(X)} $最大，由于$p(x)$是常数，因此最大后验概率估计在于求$ p(X|\mu)p(\mu) $最大。


随着我们观测到越来越多的数据，MAP估计逐步逼近MLE。当我们观测到的数据越来越多的时候，我们从数据中获取的信息的置信度是越高的。


### 贝叶斯参数估计
在估计参数之前对参数已经有了了解称为参数的先验知识。贝叶斯估计即在估计过程中将先验知识也考虑了进去。先验知识可以是一个具体的值，也可以是取值范围（函数）。实际应用中，通常会将参数的先验知识视作一个分布。

贝叶斯估计的目的是结合参数的先验知识，使得估计出来的参数能令贝叶斯风险达到最小。简单说就是最小化贝叶斯风险。

贝叶斯风险是风险函数在θ上的期望








